{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41729acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/nfs/homedirs/rachwan/Torch-Pruning/examples/yolo_example/yolov5')\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ddf60b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mexport: \u001b[0mdata=data/coco128.yaml, weights=['yolov5s.pt'], imgsz=[640, 640], batch_size=1, device=0, half=False, inplace=False, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=12, verbose=False, workspace=4, nms=False, agnostic_nms=False, topk_per_class=100, topk_all=100, iou_thres=0.45, conf_thres=0.25, include=['openvino']\n",
      "YOLOv5 ðŸš€ v6.2-186-g7f097dd Python-3.10.6 torch-1.12.1+cu113 CUDA:0 (NVIDIA GeForce RTX 2080 Ti, 11019MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from yolov5s.pt with output shape (1, 25200, 85) (14.1 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.12.0...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 6.0s, saved as yolov5s.onnx (28.0 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m starting export with openvino 2022.3.0-9052-9752fafe8eb-releases/2022/3...\n",
      "[ WARNING ]  Use of deprecated cli option --data_type detected. Option use in the following releases will be fatal. \n",
      "[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.\n",
      "Find more information about API v2.0 and IR v11 at https://docs.openvino.ai/latest/openvino_2_0_transition_guide.html\n",
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /nfs/homedirs/rachwan/Torch-Pruning/examples/yolo_example/yolov5/yolov5s_openvino_model/yolov5s.xml\n",
      "[ SUCCESS ] BIN file: /nfs/homedirs/rachwan/Torch-Pruning/examples/yolo_example/yolov5/yolov5s_openvino_model/yolov5s.bin\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m export success âœ… 32.3s, saved as yolov5s_openvino_model/ (28.2 MB)\n",
      "\n",
      "Export complete (68.1s)\n",
      "Results saved to \u001b[1m/nfs/homedirs/rachwan/Torch-Pruning/examples/yolo_example/yolov5\u001b[0m\n",
      "Detect:          python detect.py --weights yolov5s_openvino_model/ \n",
      "Validate:        python val.py --weights yolov5s_openvino_model/ \n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'yolov5s_openvino_model/')  \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "!python export.py --weights 'yolov5s.pt' --device 0 --batch-size=1 --include openvino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5747d583",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading yolov5s_openvino_model for OpenVINO inference...\n"
     ]
    }
   ],
   "source": [
    "from models.common import DetectMultiBackend\n",
    "model = DetectMultiBackend('yolov5s_openvino_model', device='cuda', dnn=False, data='data/coco.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88abd2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time': 80.0259912109375,\n",
       " 'gpu': 0.01348352,\n",
       " 'disk': 0.0,\n",
       " 'cost': 18228.6,\n",
       " 'emission': 0.29719312359407585,\n",
       " 'energy': 0.9873525700799862}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cpu()\n",
    "from evaluation_tool.models.metrics.Evaluator import Evaluator\n",
    "evaluator = Evaluator()\n",
    "\n",
    "evaluator.evaluate_inference(model, tuple([3, 640, 640]), 'cuda', iterations=100, batch_size=1, half=True)\n",
    "\n",
    "evaluator.get_all_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce33498",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
